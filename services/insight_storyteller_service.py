"""
üìñ INSIGHT STORYTELLER SERVICE V3 - COMPLET
Phases 7-8: Interpr√©tation, Storytelling, Restitution et Communication

üéØ OBJECTIFS:
- Phase 7: Interpr√©tation et Storytelling (41-45)
- Phase 8: Restitution et Communication (46-49)

‚úÖ FONCTIONNALIT√âS:
- G√©n√©ration d'insights d√©taill√©s point par point
- Recommandations actionnables avec actions concr√®tes
- Export PDF du rapport d'analyse
- Texte TTS pour narration vocale
- Documentation technique
- Donn√©es nettoy√©es disponibles
"""

import pandas as pd
import numpy as np
from typing import Dict, Any, List, Optional
import logging
from datetime import datetime
import base64
import io

logger = logging.getLogger(__name__)


class InsightStorytellerService:
    """
    üìñ SERVICE DE STORYTELLING V3 - PHASES 7-8 COMPL√àTES
    """
    
    def __init__(self):
        self.insights_generated = []
        self.recommendations = []
        
    # ==================== EXTRACTION DES R√âSULTATS EDA ====================
    
    def _extract_eda_insights(self, eda_results: Dict[str, Any]) -> Dict[str, Any]:
        """üîç Extraire les insights depuis les r√©sultats EDA"""
        extracted = {
            "summary": {},
            "clustering": {},
            "correlations": {},
            "tests": [],
            "univariate": {},
            "themes": {}
        }
        
        # R√©sum√© g√©n√©ral
        summary = eda_results.get("summary") or {}
        extracted["summary"] = {
            "total_rows": summary.get("total_rows", 0),
            "total_cols": summary.get("total_cols", 0),
            "missing_values": summary.get("missing_values", 0),
            "numeric_analyzed": summary.get("numeric_analyzed", 0),
            "categorical_analyzed": summary.get("categorical_analyzed", 0)
        }
        
        # Clustering
        metrics = eda_results.get("metrics") or {}
        multi_clustering = metrics.get("multi_clustering") or {}
        
        if multi_clustering.get("clusterings"):
            best_clustering = None
            best_score = -1
            
            for key, clustering in multi_clustering["clusterings"].items():
                score = clustering.get("silhouette_score") or 0
                if score > best_score:
                    best_score = score
                    best_clustering = clustering
            
            if best_clustering:
                extracted["clustering"] = {
                    "n_clusters": best_clustering.get("n_clusters", 0),
                    "silhouette_score": best_score,
                    "dna": best_clustering.get("dna", {}),
                    "method": best_clustering.get("method_used", ""),
                    "explanation": best_clustering.get("explanation", {}),
                    "variables_used": multi_clustering.get("variables_used", [])
                }
        
        # Corr√©lations
        correlations = metrics.get("correlations") or {}
        extracted["correlations"] = {
            "strong": correlations.get("strong_correlations", []),
            "moderate": correlations.get("moderate_correlations", []),
            "target_correlations": correlations.get("target_correlations", {})
        }
        
        # Tests statistiques significatifs
        tests = metrics.get("tests") or []
        extracted["tests"] = [t for t in tests if t.get("p_value", 1) < 0.05]
        
        # Stats univari√©es
        extracted["univariate"] = metrics.get("univariate") or {}
        
        # Th√®mes
        extracted["themes"] = metrics.get("themes") or {}
        
        return extracted
    
    # ==================== CALCUL QUALIT√â DONN√âES ====================
    
    def _calculate_data_quality(self, eda_insights: Dict[str, Any]) -> Dict[str, Any]:
        """üìä Calculer la qualit√© des donn√©es"""
        summary = eda_insights.get("summary", {})
        
        total_rows = summary.get("total_rows", 0) or 0
        total_cols = summary.get("total_cols", 0) or 0
        missing_values = summary.get("missing_values", 0) or 0
        
        total_cells = total_rows * total_cols
        if total_cells > 0:
            missing_pct = (missing_values / total_cells) * 100
        else:
            missing_pct = 0
        
        missing_pct = min(missing_pct, 100)
        completeness_pct = 100 - missing_pct
        
        if completeness_pct >= 95:
            quality_level = "excellente"
            quality_emoji = "üü¢"
        elif completeness_pct >= 85:
            quality_level = "bonne"
            quality_emoji = "üü¢"
        elif completeness_pct >= 70:
            quality_level = "acceptable"
            quality_emoji = "üü°"
        elif completeness_pct >= 50:
            quality_level = "moyenne"
            quality_emoji = "üü†"
        else:
            quality_level = "faible"
            quality_emoji = "üî¥"
        
        return {
            "total_rows": total_rows,
            "total_cols": total_cols,
            "total_cells": total_cells,
            "missing_values": missing_values,
            "missing_pct": round(missing_pct, 1),
            "completeness_pct": round(completeness_pct, 1),
            "quality_level": quality_level,
            "quality_emoji": quality_emoji
        }
    
    # ==================== PHASE 7.1: INTERPR√âTATION DES R√âSULTATS ====================
    
    def _interpret_clustering_results(self, clustering_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        üéØ 41. Interpr√©tation des r√©sultats de clustering
        Quelles variables p√®sent le plus dans la segmentation?
        """
        interpretations = []
        
        if not clustering_data or not clustering_data.get("dna"):
            return interpretations
        
        dna = clustering_data.get("dna", {})
        n_clusters = clustering_data.get("n_clusters", 0)
        silhouette = clustering_data.get("silhouette_score", 0)
        variables_used = clustering_data.get("variables_used", [])
        
        # Interpr√©tation globale
        if n_clusters >= 2:
            score_text = f"{silhouette:.2f}" if silhouette and silhouette > -1 else "N/A"
            
            if silhouette and silhouette > 0.5:
                quality_interpretation = "Les groupes sont tr√®s bien d√©finis et distincts"
            elif silhouette and silhouette > 0.25:
                quality_interpretation = "Les groupes sont raisonnablement distincts"
            elif silhouette and silhouette > 0:
                quality_interpretation = "Les groupes se chevauchent partiellement"
            else:
                quality_interpretation = "La segmentation est indicative mais les groupes ne sont pas tr√®s distincts"
            
            interpretations.append({
                "id": "clustering_global",
                "type": "segmentation",
                "title": f"üéØ {n_clusters} Segments Identifi√©s",
                "finding": f"{n_clusters} groupes distincts ont √©t√© identifi√©s dans vos donn√©es",
                "metric": f"Score de qualit√©: {score_text}",
                "interpretation": quality_interpretation,
                "variables_cles": variables_used[:5] if variables_used else [],
                "so_what": "Vous pouvez adapter vos strat√©gies selon ces segments",
                "priority": "haute" if silhouette and silhouette > 0.2 else "moyenne"
            })
        
        # Interpr√©tation par segment
        for cluster_name, cluster_info in dna.items():
            features = cluster_info.get("features", {})
            size = cluster_info.get("size", 0)
            percentage = cluster_info.get("percentage", 0)
            
            # Trouver les caract√©ristiques distinctives
            distinctive = []
            for feat_name, feat_info in features.items():
                z = feat_info.get("z_score", 0)
                if abs(z) > 0.3:
                    distinctive.append({
                        "variable": feat_name,
                        "direction": "sup√©rieur √† la moyenne" if z > 0 else "inf√©rieur √† la moyenne",
                        "magnitude": abs(z),
                        "interpretation": feat_info.get("interpretation", "")
                    })
            
            if distinctive:
                distinctive.sort(key=lambda x: x["magnitude"], reverse=True)
                
                # Cr√©er le profil du segment
                profile_text = []
                for d in distinctive[:3]:
                    profile_text.append(f"‚Ä¢ {d['variable']}: {d['direction']}")
                
                interpretations.append({
                    "id": f"cluster_{cluster_name}",
                    "type": "cluster_profile",
                    "title": f"üìä Profil: {cluster_name}",
                    "finding": f"Ce segment repr√©sente {percentage:.0f}% des donn√©es ({size} observations)",
                    "characteristics": distinctive[:5],
                    "profile_summary": "\n".join(profile_text),
                    "so_what": f"Ce groupe a des caract√©ristiques distinctes √† cibler sp√©cifiquement",
                    "priority": "moyenne"
                })
        
        return interpretations
    
    def _interpret_correlation_results(self, correlations_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        üîó Interpr√©tation des corr√©lations
        """
        interpretations = []
        
        strong_corr = correlations_data.get("strong", [])
        target_corr = correlations_data.get("target_correlations", {})
        
        # Corr√©lations fortes
        for corr in strong_corr[:5]:
            var1, var2 = corr.get("var1", ""), corr.get("var2", "")
            r = corr.get("r", 0)
            
            if abs(r) > 0.7:
                direction = "positive" if r > 0 else "n√©gative"
                
                if r > 0:
                    interpretation = f"Quand {var1} augmente, {var2} augmente aussi"
                else:
                    interpretation = f"Quand {var1} augmente, {var2} diminue"
                
                interpretations.append({
                    "id": f"corr_{var1}_{var2}",
                    "type": "correlation",
                    "title": f"üîó Relation {var1} ‚Üî {var2}",
                    "finding": f"Corr√©lation {direction} forte (r = {r:.2f})",
                    "interpretation": interpretation,
                    "variance_explained": f"{r**2*100:.0f}% de variance commune",
                    "so_what": "Ces variables sont li√©es - agir sur l'une impacte l'autre",
                    "priority": "haute"
                })
        
        # Corr√©lations avec la cible
        if target_corr:
            sorted_target = sorted(target_corr.items(), key=lambda x: abs(x[1].get("r", 0)), reverse=True)
            
            for var, info in sorted_target[:3]:
                r = info.get("r", 0)
                if abs(r) > 0.3:
                    interpretations.append({
                        "id": f"target_corr_{var}",
                        "type": "target_influence",
                        "title": f"üéØ Influence de {var}",
                        "finding": f"'{var}' influence significativement la variable cible (r = {r:.2f})",
                        "interpretation": f"Cette variable explique {r**2*100:.0f}% des variations de la cible",
                        "so_what": "Variable cl√© √† surveiller et optimiser",
                        "priority": "haute"
                    })
        
        return interpretations
    
    def _interpret_test_results(self, tests: List[Dict]) -> List[Dict[str, Any]]:
        """
        üìä Interpr√©tation des tests statistiques
        """
        interpretations = []
        
        for test in tests[:5]:
            test_type = test.get("test_type", "")
            var1, var2 = test.get("variable1", ""), test.get("variable2", "")
            p_value = test.get("p_value", 1)
            statistic = test.get("statistic", 0)
            
            if p_value < 0.05:
                confidence = "tr√®s haute (p < 0.01)" if p_value < 0.01 else "haute (p < 0.05)"
                
                if test_type == "ttest":
                    interpretations.append({
                        "id": f"test_{var1}_{var2}",
                        "type": "statistical_test",
                        "title": f"üìà Diff√©rence significative: {var2} par {var1}",
                        "finding": f"Les groupes de '{var1}' ont des valeurs de '{var2}' statistiquement diff√©rentes",
                        "test_used": "T-Test",
                        "confidence": confidence,
                        "p_value": p_value,
                        "interpretation": f"La diff√©rence observ√©e n'est pas due au hasard",
                        "so_what": f"Adapter les actions selon les groupes de '{var1}'",
                        "priority": "haute" if p_value < 0.01 else "moyenne"
                    })
                
                elif test_type == "anova":
                    interpretations.append({
                        "id": f"anova_{var1}_{var2}",
                        "type": "statistical_test",
                        "title": f"üìä Variations entre groupes: {var2}",
                        "finding": f"'{var2}' varie significativement selon '{var1}'",
                        "test_used": "ANOVA",
                        "confidence": confidence,
                        "p_value": p_value,
                        "interpretation": "Au moins un groupe se distingue des autres",
                        "so_what": "Identifier et comprendre le groupe qui se d√©marque",
                        "priority": "haute" if p_value < 0.01 else "moyenne"
                    })
        
        return interpretations
    
    # ==================== PHASE 7.2: SYNTH√àSE DES INSIGHTS ====================
    
    def _synthesize_key_insights(self, eda_insights: Dict[str, Any], 
                                  ml_results: Dict[str, Any],
                                  context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        üí° 42. Synth√®se des insights cl√©s - "So what?"
        """
        all_insights = []
        
        # 1. Insight qualit√© donn√©es
        dq = self._calculate_data_quality(eda_insights)
        all_insights.append({
            "id": "data_quality",
            "category": "Qualit√© des Donn√©es",
            "icon": dq["quality_emoji"],
            "title": f"Qualit√© des donn√©es: {dq['quality_level']}",
            "finding": f"{dq['total_rows']} observations, {dq['total_cols']} variables",
            "metric": f"{dq['completeness_pct']:.1f}% de compl√©tude",
            "so_what": "Une bonne qualit√© augmente la fiabilit√© des analyses" if dq["completeness_pct"] > 80 else "Am√©liorer la collecte pour des analyses plus fiables",
            "priority": "haute" if dq["missing_pct"] > 20 else "moyenne",
            "action_required": dq["missing_pct"] > 10
        })
        
        # 2. Insights clustering
        clustering_interp = self._interpret_clustering_results(eda_insights.get("clustering", {}))
        for interp in clustering_interp:
            all_insights.append({
                "id": interp["id"],
                "category": "Segmentation",
                "icon": "üéØ",
                "title": interp["title"],
                "finding": interp["finding"],
                "metric": interp.get("metric", ""),
                "so_what": interp["so_what"],
                "priority": interp["priority"],
                "details": interp.get("characteristics", [])
            })
        
        # 3. Insights corr√©lations
        corr_interp = self._interpret_correlation_results(eda_insights.get("correlations", {}))
        for interp in corr_interp:
            all_insights.append({
                "id": interp["id"],
                "category": "Relations",
                "icon": "üîó",
                "title": interp["title"],
                "finding": interp["finding"],
                "metric": interp.get("variance_explained", ""),
                "so_what": interp["so_what"],
                "priority": interp["priority"]
            })
        
        # 4. Insights tests
        test_interp = self._interpret_test_results(eda_insights.get("tests", []))
        for interp in test_interp:
            all_insights.append({
                "id": interp["id"],
                "category": "Tests Statistiques",
                "icon": "üìä",
                "title": interp["title"],
                "finding": interp["finding"],
                "metric": f"p-value: {interp.get('p_value', 'N/A')}",
                "so_what": interp["so_what"],
                "priority": interp["priority"]
            })
        
        # 5. Insight ML
        if ml_results:
            if ml_results.get("success"):
                best = ml_results.get("best_model") or {}
                if best.get("name"):
                    score = best.get("score", 0)
                    all_insights.append({
                        "id": "ml_success",
                        "category": "Machine Learning",
                        "icon": "ü§ñ",
                        "title": f"Mod√®le pr√©dictif: {best.get('name')}",
                        "finding": f"Performance: {score*100:.1f}%",
                        "metric": f"Algorithme: {best.get('name')}",
                        "so_what": "Le mod√®le peut √™tre utilis√© pour des pr√©dictions" if score > 0.7 else "Le mod√®le n√©cessite des am√©liorations",
                        "priority": "haute"
                    })
            else:
                all_insights.append({
                    "id": "ml_not_applicable",
                    "category": "Machine Learning",
                    "icon": "‚ö†Ô∏è",
                    "title": "Mod√©lisation non applicable",
                    "finding": ml_results.get("error", "Les donn√©es ne permettent pas d'entra√Æner un mod√®le"),
                    "metric": "N/A",
                    "so_what": "Se concentrer sur l'analyse descriptive et la segmentation",
                    "priority": "basse"
                })
        
        return all_insights
    
    # ==================== PHASE 7.3: RECOMMANDATIONS ACTIONNABLES ====================
    
    def _generate_actionable_recommendations(self, insights: List[Dict], 
                                             eda_insights: Dict,
                                             ml_results: Dict,
                                             context: Dict) -> List[Dict[str, Any]]:
        """
        üéØ 45. Formulation de recommandations actionnables
        """
        recommendations = []
        recommendation_id = 1
        
        # 1. Recommandations de segmentation
        clustering = eda_insights.get("clustering", {})
        if clustering.get("dna"):
            dna = clustering["dna"]
            n_segments = len(dna)
            
            recommendations.append({
                "id": recommendation_id,
                "title": f"Strat√©gie de Segmentation ({n_segments} Segments)",
                "category": "Segmentation",
                "priority": "haute",
                "priority_color": "#e74c3c",
                "impact": 85,
                "effort": "moyen",
                "timeline": "Court terme (2-4 semaines)",
                "description": f"D√©velopper {n_segments} approches diff√©renci√©es bas√©es sur les profils identifi√©s",
                "rationale": "La segmentation permet de personnaliser les actions et d'augmenter l'efficacit√©",
                "actions": [
                    {"step": 1, "action": "Cr√©er une fiche profil d√©taill√©e pour chaque segment", "responsible": "Analyste"},
                    {"step": 2, "action": "D√©finir les caract√©ristiques distinctives de chaque groupe", "responsible": "Marketing"},
                    {"step": 3, "action": "Adapter la communication selon les profils", "responsible": "Communication"},
                    {"step": 4, "action": "D√©finir des KPIs de suivi par segment", "responsible": "Direction"}
                ],
                "kpis": ["Taux de conversion par segment", "Satisfaction par segment", "R√©tention par segment"],
                "risks": ["Ressources n√©cessaires pour personnaliser", "Complexit√© de mise en ≈ìuvre"],
                "tts_text": f"Recommandation num√©ro {recommendation_id}: Mettre en place une strat√©gie de segmentation avec {n_segments} segments. Impact estim√©: 85%. Actions principales: cr√©er des fiches profils, adapter la communication, et d√©finir des KPIs par segment."
            })
            recommendation_id += 1
            
            # Focus sur le segment principal
            largest = max(dna.items(), key=lambda x: x[1].get("size", 0))
            recommendations.append({
                "id": recommendation_id,
                "title": f"Focus Prioritaire: {largest[0]}",
                "category": "Priorit√© Business",
                "priority": "haute",
                "priority_color": "#e74c3c",
                "impact": 75,
                "effort": "faible",
                "timeline": "Imm√©diat (1-2 semaines)",
                "description": f"Concentrer les efforts sur le segment majoritaire ({largest[1].get('percentage', 0):.0f}% des donn√©es)",
                "rationale": "Maximiser l'impact en ciblant le groupe le plus important",
                "actions": [
                    {"step": 1, "action": f"Analyser en d√©tail les caract√©ristiques de {largest[0]}", "responsible": "Analyste"},
                    {"step": 2, "action": "Identifier les besoins sp√©cifiques de ce segment", "responsible": "Produit"},
                    {"step": 3, "action": "D√©velopper une offre ou action adapt√©e", "responsible": "Commercial"},
                    {"step": 4, "action": "Mesurer les r√©sultats et ajuster", "responsible": "Marketing"}
                ],
                "kpis": ["Part de march√© du segment", "Revenu g√©n√©r√©", "Taux d'engagement"],
                "risks": ["N√©gliger les autres segments"],
                "tts_text": f"Recommandation num√©ro {recommendation_id}: Prioriser le segment {largest[0]} qui repr√©sente {largest[1].get('percentage', 0):.0f}% des donn√©es. Actions imm√©diates: analyser les caract√©ristiques et d√©velopper une offre adapt√©e."
            })
            recommendation_id += 1
        
        # 2. Recommandations bas√©es sur les corr√©lations fortes
        correlations = eda_insights.get("correlations", {})
        for corr in correlations.get("strong", [])[:2]:
            var1, var2 = corr.get("var1", ""), corr.get("var2", "")
            r = corr.get("r", 0)
            
            if abs(r) > 0.7:
                recommendations.append({
                    "id": recommendation_id,
                    "title": f"Exploiter la Relation {var1} ‚Üî {var2}",
                    "category": "Optimisation",
                    "priority": "haute" if abs(r) > 0.8 else "moyenne",
                    "priority_color": "#e74c3c" if abs(r) > 0.8 else "#f39c12",
                    "impact": int(abs(r) * 100),
                    "effort": "moyen",
                    "timeline": "Moyen terme (1-2 mois)",
                    "description": f"Ces variables ont une corr√©lation de {r:.2f} - agir sur l'une influence l'autre",
                    "rationale": f"Relation statistiquement significative ({r**2*100:.0f}% de variance commune)",
                    "actions": [
                        {"step": 1, "action": f"Cr√©er un tableau de bord combinant {var1} et {var2}", "responsible": "BI"},
                        {"step": 2, "action": "Investiguer la relation de causalit√©", "responsible": "Analyste"},
                        {"step": 3, "action": "Utiliser cette relation pour les pr√©visions", "responsible": "Data Science"},
                        {"step": 4, "action": "Monitorer conjointement ces indicateurs", "responsible": "Op√©rations"}
                    ],
                    "kpis": [f"√âvolution de {var1}", f"√âvolution de {var2}", "Ratio entre les deux"],
                    "risks": ["Corr√©lation ‚â† Causalit√© - investiguer avant d'agir"],
                    "tts_text": f"Recommandation num√©ro {recommendation_id}: Exploiter la relation entre {var1} et {var2} avec une corr√©lation de {r:.2f}. Ces variables √©voluent ensemble."
                })
                recommendation_id += 1
        
        # 3. Recommandations bas√©es sur les tests significatifs
        for test in eda_insights.get("tests", [])[:2]:
            var1, var2 = test.get("variable1", ""), test.get("variable2", "")
            if test.get("p_value", 1) < 0.05:
                recommendations.append({
                    "id": recommendation_id,
                    "title": f"Diff√©rencier par {var1}",
                    "category": "Personnalisation",
                    "priority": "moyenne",
                    "priority_color": "#f39c12",
                    "impact": 60,
                    "effort": "faible",
                    "timeline": "Court terme (2-4 semaines)",
                    "description": f"'{var2}' varie significativement selon '{var1}' (confirm√© statistiquement)",
                    "rationale": f"Test statistique significatif (p < 0.05)",
                    "actions": [
                        {"step": 1, "action": f"Analyser {var2} par groupe de {var1}", "responsible": "Analyste"},
                        {"step": 2, "action": "Identifier les diff√©rences cl√©s", "responsible": "M√©tier"},
                        {"step": 3, "action": f"Adapter les actions selon {var1}", "responsible": "Op√©rations"},
                        {"step": 4, "action": "Cr√©er des rapports segment√©s", "responsible": "BI"}
                    ],
                    "kpis": [f"{var2} par cat√©gorie de {var1}"],
                    "risks": ["Complexit√© de personnalisation"],
                    "tts_text": f"Recommandation num√©ro {recommendation_id}: Diff√©rencier les actions selon {var1} car {var2} varie significativement entre les groupes."
                })
                recommendation_id += 1
        
        # 4. Recommandation qualit√© donn√©es
        dq = self._calculate_data_quality(eda_insights)
        if dq["missing_pct"] > 10:
            recommendations.append({
                "id": recommendation_id,
                "title": "Am√©liorer la Qualit√© des Donn√©es",
                "category": "Data Quality",
                "priority": "haute" if dq["missing_pct"] > 30 else "moyenne",
                "priority_color": "#e74c3c" if dq["missing_pct"] > 30 else "#f39c12",
                "impact": 70,
                "effort": "moyen",
                "timeline": "Moyen terme (1-3 mois)",
                "description": f"Actuellement {dq['completeness_pct']:.0f}% de compl√©tude - am√©liorer la collecte",
                "rationale": "Des donn√©es compl√®tes am√©liorent la fiabilit√© des analyses",
                "actions": [
                    {"step": 1, "action": "Identifier les sources des donn√©es manquantes", "responsible": "Data Engineering"},
                    {"step": 2, "action": "Mettre en place des contr√¥les de saisie", "responsible": "IT"},
                    {"step": 3, "action": "Automatiser la validation des donn√©es", "responsible": "DevOps"},
                    {"step": 4, "action": "Former les √©quipes √† la qualit√© des donn√©es", "responsible": "Formation"}
                ],
                "kpis": ["Taux de compl√©tude", "Nombre d'erreurs de saisie", "Temps de correction"],
                "risks": ["Co√ªt de mise en ≈ìuvre", "R√©sistance au changement"],
                "tts_text": f"Recommandation num√©ro {recommendation_id}: Am√©liorer la qualit√© des donn√©es. Actuellement {dq['completeness_pct']:.0f}% de compl√©tude. Actions: identifier les sources de donn√©es manquantes et automatiser la validation."
            })
            recommendation_id += 1
        
        # 5. Recommandation ML si applicable
        if ml_results and ml_results.get("success"):
            best = ml_results.get("best_model") or {}
            if best.get("name"):
                score = best.get("score", 0)
                recommendations.append({
                    "id": recommendation_id,
                    "title": "D√©ployer le Mod√®le Pr√©dictif",
                    "category": "Machine Learning",
                    "priority": "haute" if score > 0.7 else "moyenne",
                    "priority_color": "#e74c3c" if score > 0.7 else "#f39c12",
                    "impact": int(score * 100),
                    "effort": "√©lev√©",
                    "timeline": "Moyen terme (2-3 mois)",
                    "description": f"Le mod√®le {best.get('name')} atteint {score*100:.0f}% de performance",
                    "rationale": "Automatiser les d√©cisions avec un mod√®le pr√©dictif fiable",
                    "actions": [
                        {"step": 1, "action": "Valider le mod√®le sur des donn√©es r√©centes", "responsible": "Data Science"},
                        {"step": 2, "action": "D√©velopper une API de pr√©diction", "responsible": "MLOps"},
                        {"step": 3, "action": "Int√©grer dans les processus m√©tier", "responsible": "IT"},
                        {"step": 4, "action": "Mettre en place le monitoring du mod√®le", "responsible": "Data Science"}
                    ],
                    "kpis": ["Pr√©cision en production", "Temps de r√©ponse", "Drift du mod√®le"],
                    "risks": ["Co√ªt d'infrastructure", "Maintenance continue n√©cessaire"],
                    "tts_text": f"Recommandation num√©ro {recommendation_id}: D√©ployer le mod√®le {best.get('name')} avec {score*100:.0f}% de performance. Actions: valider, d√©velopper l'API, et mettre en place le monitoring."
                })
                recommendation_id += 1
        
        # Trier par priorit√© et impact
        priority_order = {"haute": 0, "moyenne": 1, "basse": 2}
        recommendations.sort(key=lambda x: (priority_order.get(x.get("priority", "basse"), 3), -x.get("impact", 0)))
        
        return recommendations
    
    # ==================== PHASE 7.4: DATA STORYTELLING ====================
    
    def _create_data_story(self, insights: List[Dict], recommendations: List[Dict],
                           eda_insights: Dict, context: Dict) -> Dict[str, Any]:
        """
        üìñ 44. Sc√©narisation (Data Storytelling)
        Construire un r√©cit logique pour guider vers la conclusion
        """
        target = context.get("target_variable", "les donn√©es")
        dq = self._calculate_data_quality(eda_insights)
        
        # Structure narrative
        story = {
            "title": f"Analyse de {target}: D√©couvertes et D√©cisions",
            "subtitle": f"Rapport g√©n√©r√© le {datetime.now().strftime('%d/%m/%Y √† %H:%M')}",
            
            "chapters": [
                {
                    "number": 1,
                    "title": "Contexte et Donn√©es",
                    "content": f"Cette analyse porte sur un ensemble de {dq['total_rows']} observations et {dq['total_cols']} variables. "
                              f"La qualit√© des donn√©es est {dq['quality_level']} avec {dq['completeness_pct']:.0f}% de compl√©tude.",
                    "key_point": "Comprendre la structure des donn√©es est la premi√®re √©tape"
                },
                {
                    "number": 2,
                    "title": "D√©couvertes Principales",
                    "content": "\n".join([f"‚Ä¢ {i.get('finding', '')}" for i in insights[:5]]),
                    "key_point": "Ces d√©couvertes orientent les d√©cisions strat√©giques"
                },
                {
                    "number": 3,
                    "title": "Recommandations",
                    "content": "\n".join([f"‚Ä¢ {r.get('title', '')}" for r in recommendations[:5]]),
                    "key_point": "Des actions concr√®tes pour transformer les insights en r√©sultats"
                }
            ],
            
            "executive_summary": f"L'analyse de {dq['total_rows']} observations r√©v√®le {len(insights)} insights majeurs. "
                                f"La qualit√© des donn√©es est {dq['quality_level']} ({dq['completeness_pct']:.0f}% compl√©tude). "
                                f"{len([r for r in recommendations if r.get('priority') == 'haute'])} recommandations prioritaires sont identifi√©es.",
            
            "conclusion": "Cette analyse fournit une base solide pour la prise de d√©cision. "
                         "Les recommandations sont class√©es par priorit√© et impact pour faciliter la mise en ≈ìuvre."
        }
        
        # TTS Narration compl√®te
        tts_parts = [
            f"Rapport d'analyse de {target}.",
            f"Ce rapport est bas√© sur {dq['total_rows']} observations.",
            f"La qualit√© des donn√©es est {dq['quality_level']} avec {dq['completeness_pct']:.0f} pour cent de compl√©tude."
        ]
        
        # Ajouter les insights principaux
        tts_parts.append("Voici les principales d√©couvertes:")
        for i, insight in enumerate(insights[:3], 1):
            tts_parts.append(f"D√©couverte {i}: {insight.get('finding', '')}. {insight.get('so_what', '')}.")
        
        # Ajouter les recommandations
        tts_parts.append("Passons maintenant aux recommandations:")
        for rec in recommendations[:3]:
            if rec.get("tts_text"):
                tts_parts.append(rec["tts_text"])
        
        tts_parts.append("Fin du rapport. Consultez le document PDF pour les d√©tails complets.")
        
        story["tts_narration"] = " ".join(tts_parts)
        
        return story
    
    # ==================== PHASE 8: G√âN√âRATION DE RAPPORTS ====================
    
    def _generate_pdf_report_content(self, insights: List[Dict], recommendations: List[Dict],
                                     eda_insights: Dict, context: Dict) -> Dict[str, Any]:
        """
        üìÑ 46. Contenu pour le rapport PDF
        """
        dq = self._calculate_data_quality(eda_insights)
        target = context.get("target_variable", "les donn√©es")
        
        return {
            "title": f"Rapport d'Analyse: {target}",
            "generated_at": datetime.now().isoformat(),
            "generated_at_formatted": datetime.now().strftime("%d/%m/%Y √† %H:%M"),
            
            "summary": {
                "observations": dq["total_rows"],
                "variables": dq["total_cols"],
                "completeness": f"{dq['completeness_pct']:.1f}%",
                "quality": dq["quality_level"],
                "insights_count": len(insights),
                "recommendations_count": len(recommendations),
                "high_priority_count": len([r for r in recommendations if r.get("priority") == "haute"])
            },
            
            "insights": insights,
            "recommendations": recommendations,
            
            "methodology": {
                "phases": [
                    "Phase 1-4: Exploration et pr√©paration des donn√©es",
                    "Phase 5: Feature Engineering (cr√©ation de variables)",
                    "Phase 6: Machine Learning (si applicable)",
                    "Phase 7: Interpr√©tation et Storytelling",
                    "Phase 8: Restitution et Communication"
                ],
                "tools_used": ["Python", "Scikit-learn", "Pandas", "NumPy"],
                "statistical_tests": ["T-Test", "ANOVA", "Corr√©lation de Pearson"]
            },
            
            "appendix": {
                "data_quality_details": dq,
                "variables_analyzed": {
                    "numeric": eda_insights.get("summary", {}).get("numeric_analyzed", 0),
                    "categorical": eda_insights.get("summary", {}).get("categorical_analyzed", 0)
                }
            }
        }
    
    def _generate_markdown_report(self, insights: List[Dict], recommendations: List[Dict],
                                  eda_insights: Dict, context: Dict) -> str:
        """üìù Rapport Markdown complet"""
        dq = self._calculate_data_quality(eda_insights)
        target = context.get("target_variable", "les donn√©es")
        
        md = [
            f"# üìä Rapport d'Analyse: {target}",
            f"",
            f"*G√©n√©r√© le {datetime.now().strftime('%d/%m/%Y √† %H:%M')}*",
            f"",
            f"---",
            f"",
            f"## üìã R√©sum√© Ex√©cutif",
            f"",
            f"| M√©trique | Valeur |",
            f"|----------|--------|",
            f"| Observations | {dq['total_rows']} |",
            f"| Variables | {dq['total_cols']} |",
            f"| Compl√©tude | {dq['completeness_pct']:.1f}% |",
            f"| Qualit√© | {dq['quality_level'].capitalize()} |",
            f"| Insights | {len(insights)} |",
            f"| Recommandations | {len(recommendations)} |",
            f"",
            f"---",
            f"",
            f"## üí° Insights Cl√©s",
            f""
        ]
        
        for i, insight in enumerate(insights, 1):
            priority_emoji = "üî¥" if insight.get("priority") == "haute" else "üü°" if insight.get("priority") == "moyenne" else "üü¢"
            md.append(f"### {i}. {insight.get('title', insight.get('category', 'Insight'))} {priority_emoji}")
            md.append(f"")
            md.append(f"**Constat:** {insight.get('finding', '')}")
            md.append(f"")
            if insight.get('metric'):
                md.append(f"**M√©trique:** {insight.get('metric', '')}")
                md.append(f"")
            md.append(f"**Implication:** {insight.get('so_what', '')}")
            md.append(f"")
        
        md.append(f"---")
        md.append(f"")
        md.append(f"## üéØ Recommandations Actionnables")
        md.append(f"")
        
        for rec in recommendations:
            priority_badge = "üî¥ HAUTE" if rec.get("priority") == "haute" else "üü° MOYENNE" if rec.get("priority") == "moyenne" else "üü¢ BASSE"
            md.append(f"### {rec.get('id', '')}. {rec.get('title', '')}")
            md.append(f"")
            md.append(f"**Priorit√©:** {priority_badge} | **Impact:** {rec.get('impact', 0)}% | **Effort:** {rec.get('effort', '')} | **Timeline:** {rec.get('timeline', '')}")
            md.append(f"")
            md.append(f"{rec.get('description', '')}")
            md.append(f"")
            md.append(f"**Justification:** {rec.get('rationale', '')}")
            md.append(f"")
            md.append(f"**Actions concr√®tes:**")
            for action in rec.get("actions", []):
                md.append(f"- **√âtape {action.get('step', '')}:** {action.get('action', '')} *(Responsable: {action.get('responsible', '')})*")
            md.append(f"")
            md.append(f"**KPIs de suivi:** {', '.join(rec.get('kpis', []))}")
            md.append(f"")
        
        md.append(f"---")
        md.append(f"")
        md.append(f"## üìö M√©thodologie")
        md.append(f"")
        md.append(f"Ce rapport a √©t√© g√©n√©r√© automatiquement en suivant les phases d'analyse de donn√©es:")
        md.append(f"")
        md.append(f"1. **Phases 1-4:** Exploration et pr√©paration des donn√©es")
        md.append(f"2. **Phase 5:** Feature Engineering (cr√©ation de variables)")
        md.append(f"3. **Phase 6:** Machine Learning (si applicable)")
        md.append(f"4. **Phase 7:** Interpr√©tation et Storytelling")
        md.append(f"5. **Phase 8:** Restitution et Communication")
        md.append(f"")
        md.append(f"---")
        md.append(f"")
        md.append(f"*Rapport g√©n√©r√© automatiquement par le syst√®me d'analyse intelligente.*")
        
        return "\n".join(md)
    
    def _generate_html_report(self, insights: List[Dict], recommendations: List[Dict],
                              eda_insights: Dict, context: Dict) -> str:
        """üìÑ Rapport HTML stylis√©"""
        dq = self._calculate_data_quality(eda_insights)
        target = context.get("target_variable", "les donn√©es")
        
        insights_html = ""
        for i, insight in enumerate(insights, 1):
            priority_class = "high" if insight.get("priority") == "haute" else "medium" if insight.get("priority") == "moyenne" else "low"
            insights_html += f"""
            <div class="insight {priority_class}">
                <div class="insight-header">
                    <span class="insight-icon">{insight.get('icon', 'üí°')}</span>
                    <h3>{insight.get('title', insight.get('category', 'Insight'))}</h3>
                </div>
                <p class="finding"><strong>Constat:</strong> {insight.get('finding', '')}</p>
                <p class="metric"><strong>M√©trique:</strong> {insight.get('metric', 'N/A')}</p>
                <p class="so-what"><strong>Implication:</strong> {insight.get('so_what', '')}</p>
            </div>
            """
        
        recommendations_html = ""
        for rec in recommendations:
            actions_html = "".join([
                f"<li><strong>√âtape {a.get('step', '')}:</strong> {a.get('action', '')} <em>({a.get('responsible', '')})</em></li>"
                for a in rec.get("actions", [])
            ])
            
            recommendations_html += f"""
            <div class="recommendation">
                <div class="rec-header">
                    <span class="rec-number">{rec.get('id', '')}</span>
                    <h3>{rec.get('title', '')}</h3>
                </div>
                <div class="rec-meta">
                    <span class="priority priority-{rec.get('priority', 'moyenne')}">{rec.get('priority', '').upper()}</span>
                    <span class="impact">Impact: {rec.get('impact', 0)}%</span>
                    <span class="effort">Effort: {rec.get('effort', '')}</span>
                    <span class="timeline">{rec.get('timeline', '')}</span>
                </div>
                <p class="description">{rec.get('description', '')}</p>
                <p class="rationale"><strong>Justification:</strong> {rec.get('rationale', '')}</p>
                <div class="actions-list">
                    <h4>Actions concr√®tes:</h4>
                    <ol>{actions_html}</ol>
                </div>
                <div class="kpis">
                    <strong>KPIs:</strong> {', '.join(rec.get('kpis', []))}
                </div>
            </div>
            """
        
        html = f"""<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Rapport d'Analyse - {target}</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background: #f5f7fa; color: #333; line-height: 1.6; }}
        .container {{ max-width: 1000px; margin: 0 auto; padding: 20px; }}
        
        header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 40px; border-radius: 10px; margin-bottom: 30px; }}
        header h1 {{ font-size: 2.5em; margin-bottom: 10px; }}
        header .subtitle {{ opacity: 0.9; font-size: 1.1em; }}
        
        .summary-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 15px; margin-bottom: 30px; }}
        .summary-card {{ background: white; padding: 20px; border-radius: 10px; text-align: center; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        .summary-card .value {{ font-size: 2em; font-weight: bold; color: #667eea; }}
        .summary-card .label {{ color: #666; font-size: 0.9em; }}
        
        section {{ background: white; padding: 30px; border-radius: 10px; margin-bottom: 20px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        section h2 {{ color: #2c3e50; margin-bottom: 20px; padding-bottom: 10px; border-bottom: 2px solid #667eea; }}
        
        .insight {{ padding: 20px; border-radius: 8px; margin-bottom: 15px; border-left: 4px solid #667eea; background: #f8f9ff; }}
        .insight.high {{ border-left-color: #e74c3c; background: #fef5f5; }}
        .insight.medium {{ border-left-color: #f39c12; background: #fffdf5; }}
        .insight-header {{ display: flex; align-items: center; gap: 10px; margin-bottom: 10px; }}
        .insight-icon {{ font-size: 1.5em; }}
        .insight h3 {{ color: #2c3e50; }}
        .insight p {{ margin: 8px 0; }}
        .so-what {{ color: #27ae60; font-style: italic; }}
        
        .recommendation {{ background: #f8f9fa; padding: 25px; border-radius: 10px; margin-bottom: 20px; border: 1px solid #e0e0e0; }}
        .rec-header {{ display: flex; align-items: center; gap: 15px; margin-bottom: 15px; }}
        .rec-number {{ background: #667eea; color: white; width: 35px; height: 35px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-weight: bold; }}
        .rec-header h3 {{ color: #2c3e50; }}
        .rec-meta {{ display: flex; gap: 10px; flex-wrap: wrap; margin-bottom: 15px; }}
        .rec-meta span {{ padding: 5px 12px; border-radius: 20px; font-size: 0.85em; }}
        .priority {{ font-weight: bold; color: white; }}
        .priority-haute {{ background: #e74c3c; }}
        .priority-moyenne {{ background: #f39c12; }}
        .priority-basse {{ background: #27ae60; }}
        .impact, .effort, .timeline {{ background: #e8e8e8; color: #333; }}
        .description {{ font-size: 1.1em; margin-bottom: 15px; }}
        .rationale {{ color: #666; margin-bottom: 15px; }}
        .actions-list {{ background: #e8f5e9; padding: 15px; border-radius: 8px; margin-bottom: 15px; }}
        .actions-list h4 {{ color: #27ae60; margin-bottom: 10px; }}
        .actions-list ol {{ margin-left: 20px; }}
        .actions-list li {{ margin-bottom: 8px; }}
        .kpis {{ color: #667eea; font-size: 0.95em; }}
        
        footer {{ text-align: center; padding: 20px; color: #666; font-size: 0.9em; }}
        
        @media print {{
            body {{ background: white; }}
            .container {{ max-width: 100%; }}
            header {{ background: #667eea !important; -webkit-print-color-adjust: exact; print-color-adjust: exact; }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üìä Rapport d'Analyse</h1>
            <p class="subtitle">{target} - {datetime.now().strftime('%d/%m/%Y √† %H:%M')}</p>
        </header>
        
        <div class="summary-grid">
            <div class="summary-card">
                <div class="value">{dq['total_rows']}</div>
                <div class="label">Observations</div>
            </div>
            <div class="summary-card">
                <div class="value">{dq['total_cols']}</div>
                <div class="label">Variables</div>
            </div>
            <div class="summary-card">
                <div class="value">{dq['completeness_pct']:.0f}%</div>
                <div class="label">Compl√©tude</div>
            </div>
            <div class="summary-card">
                <div class="value">{len(insights)}</div>
                <div class="label">Insights</div>
            </div>
            <div class="summary-card">
                <div class="value">{len(recommendations)}</div>
                <div class="label">Recommandations</div>
            </div>
        </div>
        
        <section>
            <h2>üí° Insights Cl√©s</h2>
            {insights_html}
        </section>
        
        <section>
            <h2>üéØ Recommandations Actionnables</h2>
            {recommendations_html}
        </section>
        
        <footer>
            <p>Rapport g√©n√©r√© automatiquement par le syst√®me d'analyse intelligente</p>
        </footer>
    </div>
</body>
</html>"""
        
        return html
    
    # ==================== M√âTHODE PRINCIPALE ====================
    
    async def tell_the_story(self, eda_results: Dict[str, Any],
                             ml_results: Dict[str, Any],
                             feature_engineering: Dict[str, Any],
                             context: Dict[str, Any],
                             options: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        üìñ PIPELINE COMPLET PHASES 7-8
        
        Phase 7: Interpr√©tation et Storytelling
        - 41. Interpr√©tation des r√©sultats
        - 42. Synth√®se des insights cl√©s
        - 43. Cr√©ation de supports visuels
        - 44. Sc√©narisation (Data Storytelling)
        - 45. Formulation de recommandations actionnables
        
        Phase 8: Restitution et Communication
        - 46. R√©daction du rapport d'analyse
        - 47. Pr√©sentation orale (TTS)
        - 48. Documentation technique
        - 49. Mise √† disposition des donn√©es nettoy√©es
        """
        
        logger.info("=" * 60)
        logger.info("üìñ STORYTELLER V3 - PHASES 7-8 COMPL√àTES")
        logger.info("=" * 60)
        
        result = {
            "success": True,
            "insights": [],
            "recommendations": [],
            "story": {},
            "report": {},
            "exports": {},
            "tts_text": "",
            "tts_sections": [],
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            # Phase 7.1: Extraction et interpr√©tation
            logger.info("üîç Phase 7.1: Extraction des r√©sultats EDA...")
            eda_insights = self._extract_eda_insights(eda_results or {})
            
            # Calcul qualit√©
            dq = self._calculate_data_quality(eda_insights)
            logger.info(f"   Compl√©tude: {dq['completeness_pct']:.1f}%")
            
            # Phase 7.2: Synth√®se des insights
            logger.info("üí° Phase 7.2: Synth√®se des insights...")
            insights = self._synthesize_key_insights(eda_insights, ml_results or {}, context)
            result["insights"] = insights
            logger.info(f"   {len(insights)} insights g√©n√©r√©s")
            
            # Phase 7.3: Recommandations actionnables
            logger.info("üéØ Phase 7.3: Recommandations actionnables...")
            recommendations = self._generate_actionable_recommendations(
                insights, eda_insights, ml_results or {}, context
            )
            result["recommendations"] = recommendations
            logger.info(f"   {len(recommendations)} recommandations g√©n√©r√©es")
            
            # Phase 7.4: Data Storytelling
            logger.info("üìñ Phase 7.4: Data Storytelling...")
            story = self._create_data_story(insights, recommendations, eda_insights, context)
            result["story"] = story
            result["tts_text"] = story.get("tts_narration", "")
            
            # Sections TTS individuelles pour le frontend
            result["tts_sections"] = [
                {"id": "intro", "title": "Introduction", "text": f"Analyse de {context.get('target_variable', 'vos donn√©es')} bas√©e sur {dq['total_rows']} observations."},
                {"id": "quality", "title": "Qualit√©", "text": f"La qualit√© des donn√©es est {dq['quality_level']} avec {dq['completeness_pct']:.0f} pour cent de compl√©tude."},
            ]
            
            for i, insight in enumerate(insights[:5], 1):
                result["tts_sections"].append({
                    "id": f"insight_{i}",
                    "title": f"Insight {i}",
                    "text": f"{insight.get('finding', '')}. {insight.get('so_what', '')}"
                })
            
            for rec in recommendations[:5]:
                result["tts_sections"].append({
                    "id": f"rec_{rec.get('id', '')}",
                    "title": f"Recommandation {rec.get('id', '')}",
                    "text": rec.get("tts_text", rec.get("description", ""))
                })
            
            # Phase 8.1: G√©n√©ration du rapport
            logger.info("üìÑ Phase 8.1: G√©n√©ration du rapport...")
            result["report"] = self._generate_pdf_report_content(insights, recommendations, eda_insights, context)
            
            # Phase 8.2: Exports
            logger.info("üì§ Phase 8.2: G√©n√©ration des exports...")
            result["exports"] = {
                "markdown": self._generate_markdown_report(insights, recommendations, eda_insights, context),
                "html": self._generate_html_report(insights, recommendations, eda_insights, context)
            }
            
            logger.info("=" * 60)
            logger.info(f"‚úÖ STORYTELLER V3 TERMIN√â")
            logger.info(f"   Insights: {len(insights)}")
            logger.info(f"   Recommandations: {len(recommendations)}")
            logger.info(f"   Sections TTS: {len(result['tts_sections'])}")
            logger.info("=" * 60)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur Storyteller: {e}", exc_info=True)
            result["success"] = False
            result["error"] = str(e)
        
        return result


# Instance globale
insight_storyteller_service = InsightStorytellerService()