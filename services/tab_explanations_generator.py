"""
üìù G√âN√âRATEUR D'EXPLICATIONS PAR ONGLET - MULTI-LLM + ROBUSTE
G√®re Claude, Gemini, GPT-4 avec fallback intelligent
Extraction JSON agressive pour √©viter les parse errors
‚úÖ FIX: Gestion de multi_clustering None
"""

import json
import logging
import os
import asyncio
from typing import Dict, Any, List, Optional
from anthropic import Anthropic

logger = logging.getLogger(__name__)


def _extract_json_robust(text: str) -> Optional[Dict]:
    """Extraction JSON AGRESSIVE - priorise le r√©sultat valide"""
    
    if not text:
        return None
    
    # 1Ô∏è‚É£ NETTOYAGE INITIAL
    text = text.replace('```json', '').replace('```', '').strip()
    
    # 2Ô∏è‚É£ ESSAI DIRECT
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        pass
    
    # 3Ô∏è‚É£ CHERCHER LE JSON VALIDE LE PLUS LONG
    logger.warning(f"‚ö†Ô∏è JSON parse error, searching for valid JSON...")
    
    # Chercher tous les '{' et '}'
    start_indices = [i for i, c in enumerate(text) if c == '{']
    
    if not start_indices:
        logger.error("‚ùå Aucun '{' trouv√©, retour fallback")
        return None
    
    # Pour chaque position de d√©part, chercher le JSON valide
    best_json = None
    best_length = 0
    
    for start in start_indices:
        # Chercher le '}' correspondant
        depth = 0
        for end in range(start, len(text)):
            if text[end] == '{':
                depth += 1
            elif text[end] == '}':
                depth -= 1
                if depth == 0:
                    # Trouv√© un candidate JSON
                    candidate = text[start:end+1]
                    try:
                        parsed = json.loads(candidate)
                        if len(candidate) > best_length:
                            best_json = parsed
                            best_length = len(candidate)
                            logger.info(f"‚úÖ JSON valide trouv√©: {len(candidate)} chars")
                        break
                    except:
                        pass
    
    return best_json


class TabExplanationsGenerator:
    """G√©n√®re les explications par onglet avec Multi-LLM - AM√âLIOR√â POUR CLUSTERING"""

    @staticmethod
    def create_tab_explanation_tasks(eda_data: Dict[str, Any], 
                                     context: Dict[str, Any]) -> List[Dict[str, str]]:
        """Cr√©e les t√¢ches avec CONTEXTE complet - INCLUT CLUSTERING D√âTAILL√â"""
        
        tasks = []
        univariate = eda_data.get('univariate', {})
        multi_clustering = eda_data.get('multi_clustering') or {}  # ‚úÖ FIX: G√©rer None
        tests = eda_data.get('tests', [])
        correlations = eda_data.get('correlations', {})
        
        target = context.get('target_variable', 'Unknown')
        analysis_type = context.get('analysis_type', 'descriptive')
        focus_vars = context.get('focus_variables', [])
        
        n_num = len([s for s in univariate.values() if s.get('type') == 'numeric'])
        n_cat = len([s for s in univariate.values() if s.get('type') == 'categorical'])
        
        # ===== TASK 1: OVERVIEW =====
        overview_data = {
            "total_vars": len(univariate),
            "numeric": n_num,
            "categorical": n_cat,
            "target": target,
            "analysis_type": analysis_type,
            "rows": eda_data.get('rows', 0),
            "columns": eda_data.get('cols', 0),
            "focus_variables": focus_vars[:5]
        }
        
        tasks.append({
            "task_id": "overview",
            "prompt": f"""Analyse ce dataset et r√©ponds UNIQUEMENT avec du JSON valide.

CONTEXTE: {analysis_type}
CIBLE: {target}
VARIABLES FOCUS: {', '.join(focus_vars[:3]) if focus_vars else 'Aucune'}

DONN√âES:
- {eda_data.get('rows', 0)} lignes, {eda_data.get('cols', 0)} colonnes
- {n_num} variables num√©riques, {n_cat} variables cat√©gorielles
- Cible: {target}

R√©ponds AVEC CE FORMAT EXACT (rien d'autre):
{{
  "title": "Synth√®se du Dataset",
  "summary": "2-3 phrases d√©crivant le dataset et son objectif",
  "recommendation": "Actions concr√®tes √† prendre",
  "details": {{
    "points_cles": ["point1", "point2"],
    "complexite": "simple/moyenne/complexe"
  }}
}}""",
            "data": json.dumps(overview_data)
        })
        
        # ===== TASK 2: STATISTICS =====
        numeric_stats = [{"var": var, "cv": s.get('cv', 0), "skew": s.get('skew', 0)} 
                        for var, s in univariate.items() 
                        if s.get('type') == 'numeric'][:5]
        
        stats_summary = {
            "numeric": n_num,
            "categorical": n_cat,
            "high_variance": len([s for s in numeric_stats if s.get('cv', 0) > 1.0]),
            "high_skew": sum(1 for s in numeric_stats if abs(s.get('skew', 0)) > 1.0),
            "target": target,
            "missing_data": sum(1 for s in univariate.values() if s.get('missing_pct', 0) > 20)
        }
        
        tasks.append({
            "task_id": "stats",
            "prompt": f"""Analyse ces statistiques descriptives et r√©ponds UNIQUEMENT avec du JSON valide:

DONN√âES: {json.dumps(stats_summary)}

POINTS IMPORTANTS:
- {stats_summary['high_variance']} variables √† haute variance
- {stats_summary['high_skew']} variables tr√®s asym√©triques
- {stats_summary['missing_data']} variables avec >20% de donn√©es manquantes

R√©ponds AVEC CE FORMAT:
{{
  "title": "Statistiques Descriptives",
  "summary": "Analyse de la distribution des variables",
  "recommendation": "Conseils pour le nettoyage et la pr√©paration",
  "details": {{
    "qualite_donnees": "bonne/moyenne/faible",
    "alertes": ["alerte1", "alerte2"]
  }}
}}""",
            "data": json.dumps(stats_summary)
        })
        
        # ===== TASK 3: CHARTS =====
        tasks.append({
            "task_id": "charts",
            "prompt": f"""Recommande des visualisations pour {analysis_type} avec cible {target}. R√©ponds UNIQUEMENT avec du JSON valide:

VARIABLES DISPONIBLES:
- Num√©riques: {n_num} variables
- Cat√©gorielles: {n_cat} variables

R√©ponds AVEC CE FORMAT:
{{
  "title": "Visualisations Recommand√©es",
  "summary": "Types de graphiques les plus pertinents",
  "recommendation": "Ordre de priorit√© pour les visualisations",
  "details": {{
    "graphiques_prioritaires": ["graph1", "graph2"],
    "variables_a_visualiser": ["var1", "var2"]
  }}
}}""",
            "data": ""
        })
        
        # ===== TASK 4: TESTS =====
        tests_count = len(tests)
        significant = len([t for t in tests if t.get('p_value', 1) < 0.05])
        
        tasks.append({
            "task_id": "tests",
            "prompt": f"""Analyse ces tests statistiques ({tests_count} tests, {significant} significatifs). R√©ponds UNIQUEMENT avec du JSON valide:

CONTEXTE: Analyse de {target}

R√âSULTATS:
- Tests totaux: {tests_count}
- Tests significatifs (p<0.05): {significant}
- Taux de significativit√©: {significant/tests_count*100 if tests_count>0 else 0:.1f}%

R√©ponds AVEC CE FORMAT:
{{
  "title": "Tests Statistiques",
  "summary": "√âvaluation de la significativit√© des relations",
  "recommendation": "Interpr√©tation des r√©sultats significatifs",
  "details": {{
    "confiance": "√©lev√©e/moyenne/faible",
    "relations_importantes": ["relation1", "relation2"]
  }}
}}""",
            "data": json.dumps({"total": tests_count, "significant": significant})
        })
        
        # ===== TASK 5: CLUSTERING - AM√âLIOR√â + FIX None =====
        # ‚úÖ FIX: V√©rifier si multi_clustering est None ou vide
        clusterings = multi_clustering.get('clusterings', {}) if multi_clustering else {}
        n_clusterings = len(clusterings)
        
        # Collecter des informations d√©taill√©es sur le clustering
        clustering_info = {
            "total_models": n_clusterings,
            "models": [],
            "best_model": None,
            "best_score": 0
        }
        
        if clusterings:  # ‚úÖ FIX: V√©rifier si clusterings n'est pas vide
            for key, clust in clusterings.items():
                if clust is None:  # ‚úÖ FIX: Skip si cluster None
                    continue
                    
                model_info = {
                    "name": clust.get('name', key),
                    "clusters": clust.get('n_clusters', 0),
                    "silhouette": clust.get('silhouette_score', 0),
                    "validation": clust.get('validation', {})
                }
                clustering_info["models"].append(model_info)
                
                score = clust.get('silhouette_score', 0) or 0
                if score > clustering_info["best_score"]:
                    clustering_info["best_score"] = score
                    clustering_info["best_model"] = model_info
        
        tasks.append({
            "task_id": "clustering",
            "prompt": f"""Analyse ces r√©sultats de clustering et r√©ponds UNIQUEMENT avec du JSON valide:

DONN√âES DE CLUSTERING D√âTAILL√âES:
{json.dumps(clustering_info, indent=2)}

POINTS CL√âS:
- {n_clusterings} mod√®les de clustering g√©n√©r√©s
- Meilleur mod√®le: {clustering_info['best_model']['name'] if clustering_info['best_model'] else 'Aucun'}
- Score silhouette du meilleur mod√®le: {clustering_info['best_score']:.3f}
- Groupes identifi√©s: {', '.join([str(m['clusters']) for m in clustering_info['models']]) if clustering_info['models'] else 'Aucun'}

R√©ponds AVEC CE FORMAT:
{{
  "title": "Segmentation et Groupes",
  "summary": "Analyse d√©taill√©e des clusters identifi√©s ou raison de l'absence de clustering",
  "recommendation": "Utilisation pratique des segments ou suggestions alternatives",
  "details": {{
    "qualite_clustering": "excellente/bonne/moyenne/faible/non_applicable",
    "nombre_groupes_optimal": 3,
    "caracteristiques_cles": ["carac1", "carac2"],
    "applications": ["application1", "application2"]
  }},
  "tts_text": "Texte complet √† lire pour la synth√®se vocale (200-300 mots)"
}}""",
            "data": json.dumps(clustering_info)
        })
        
        # ===== TASK 6: CORRELATIONS =====
        strong_corr = len(correlations.get('strong_correlations', []))
        moderate_corr = len(correlations.get('moderate_correlations', []))
        target_corr = len(correlations.get('target_correlations', {}))
        
        tasks.append({
            "task_id": "correlation",
            "prompt": f"""Analyse les corr√©lations ({strong_corr} fortes, {moderate_corr} mod√©r√©es, {target_corr} avec la cible). R√©ponds UNIQUEMENT avec du JSON valide:

ANALYSE:
- Corr√©lations fortes (>0.7): {strong_corr}
- Corr√©lations mod√©r√©es (0.4-0.7): {moderate_corr}
- Corr√©lations avec {target}: {target_corr}

IMPLICATIONS:
- Fortes corr√©lations peuvent indiquer de la multicolin√©arit√©
- Corr√©lations avec la cible sont importantes pour la pr√©diction

R√©ponds AVEC CE FORMAT:
{{
  "title": "Matrice de Corr√©lation",
  "summary": "Analyse des relations lin√©aires entre variables",
  "recommendation": "Actions bas√©es sur les corr√©lations",
  "details": {{
    "intensite_relations": "forte/moyenne/faible",
    "multicolinearite": "pr√©sente/absente",
    "variables_liees_cible": ["var1", "var2"]
  }}
}}""",
            "data": json.dumps({"strong": strong_corr, "moderate": moderate_corr, "target": target_corr})
        })
        
        logger.info(f"üìù {len(tasks)} t√¢ches cr√©√©es avec clustering d√©taill√©")
        return tasks

    @staticmethod
    def create_summary_eda_data(eda_results: Dict[str, Any]) -> Dict[str, Any]:
        """Cr√©e le dictionnaire EDA pour explications"""
        metrics = eda_results.get('metrics', {})
        univariate = metrics.get('univariate', {})
        
        n_num = len([s for s in univariate.values() if s.get('type') == 'numeric'])
        n_cat = len([s for s in univariate.values() if s.get('type') == 'categorical'])
        
        return {
            "rows": eda_results.get('summary', {}).get('total_rows', 0),
            "cols": eda_results.get('summary', {}).get('total_cols', 0),
            "univariate": univariate,
            "multi_clustering": metrics.get('multi_clustering'),  # ‚úÖ Peut √™tre None
            "tests": metrics.get('tests', []),
            "correlations": metrics.get('correlations', {}),
            "missing_pct": (eda_results.get('summary', {}).get('missing_values', 0) / 
                          max(1, eda_results.get('summary', {}).get('total_rows', 1))) * 100,
            "clustering_explanations": eda_results.get('charts_data', {}).get('clustering_explanations', {})
        }


async def _call_anthropic(prompt: str) -> Optional[Dict]:
    """Appel Claude avec extraction JSON robuste"""
    try:
        from config.settings import settings
        client = Anthropic(api_key=settings.anthropic_api_key_1)
        
        message = client.messages.create(
            model="claude-3-opus-20240229",
            max_tokens=1000,
            messages=[{"role": "user", "content": prompt}]
        )
        
        response_text = message.content[0].text
        result = _extract_json_robust(response_text)
        
        if result:
            logger.info(f"‚úÖ Claude OK: {result.get('title', 'N/A')}")
            return result
        else:
            logger.warning(f"‚ö†Ô∏è Claude JSON invalid")
            return None
            
    except Exception as e:
        logger.warning(f"‚ùå Claude failed: {e}")
        return None


async def _call_gemini(prompt: str) -> Optional[Dict]:
    """Appel Gemini via API"""
    try:
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            return None
        
        import google.generativeai as genai
        genai.configure(api_key=api_key)
        
        model = genai.GenerativeModel("gemini-1.5-pro")
        response = model.generate_content(prompt)
        
        result = _extract_json_robust(response.text)
        
        if result:
            logger.info(f"‚úÖ Gemini OK: {result.get('title', 'N/A')}")
            return result
        else:
            logger.warning(f"‚ö†Ô∏è Gemini JSON invalid")
            return None
            
    except Exception as e:
        logger.warning(f"‚ùå Gemini failed: {e}")
        return None


async def _call_gpt4(prompt: str) -> Optional[Dict]:
    """Appel GPT-4 via OpenAI"""
    try:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            return None
        
        from openai import AsyncOpenAI
        
        client = AsyncOpenAI(api_key=api_key)
        response = await client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=800
        )
        
        response_text = response.choices[0].message.content
        result = _extract_json_robust(response_text)
        
        if result:
            logger.info(f"‚úÖ GPT-4 OK: {result.get('title', 'N/A')}")
            return result
        else:
            logger.warning(f"‚ö†Ô∏è GPT-4 JSON invalid")
            return None
            
    except Exception as e:
        logger.warning(f"‚ùå GPT-4 failed: {e}")
        return None


async def _generate_fallback_explanation(task_id: str, context: Dict, eda_data: Dict) -> Dict:
    """G√©n√®re une explication par d√©faut si tous les LLM √©chouent"""
    fallbacks = {
        "overview": {
            "title": "Synth√®se du Dataset",
            "summary": f"Dataset de {eda_data.get('rows', 0)} observations avec {eda_data.get('cols', 0)} variables. Analyse {context.get('analysis_type', 'exploratoire')} focalis√©e sur {context.get('target_variable', 'la variable cible')}.",
            "recommendation": "Examinez les statistiques descriptives pour comprendre la distribution des donn√©es.",
            "tts_text": f"Le dataset contient {eda_data.get('rows', 0)} observations et {eda_data.get('cols', 0)} variables. L'analyse est de type {context.get('analysis_type', 'exploratoire')} avec pour cible {context.get('target_variable', 'la variable principale')}."
        },
        "stats": {
            "title": "Statistiques Descriptives",
            "summary": f"Analyse univari√©e des variables. {len([v for v in eda_data.get('univariate', {}).values() if v.get('type') == 'numeric'])} variables num√©riques et {len([v for v in eda_data.get('univariate', {}).values() if v.get('type') == 'categorical'])} cat√©gorielles analys√©es.",
            "recommendation": "V√©rifiez les valeurs manquantes et les distributions avant toute mod√©lisation.",
            "tts_text": "Les statistiques descriptives montrent la distribution de chaque variable. Examinez les moyennes, √©carts-types et pourcentages de donn√©es manquantes."
        },
        "charts": {
            "title": "Visualisations Recommand√©es",
            "summary": "Plusieurs types de visualisations sont pertinents pour explorer ces donn√©es.",
            "recommendation": "Commencez par des histogrammes pour les variables num√©riques et des diagrammes en secteurs pour les cat√©gorielles.",
            "tts_text": "Pour visualiser ces donn√©es, je recommande des histogrammes pour les variables continues, des diagrammes en secteurs pour les cat√©gories, et des nuages de points pour les relations entre variables."
        },
        "tests": {
            "title": "Tests Statistiques",
            "summary": f"{len(eda_data.get('tests', []))} tests effectu√©s pour valider les relations entre variables.",
            "recommendation": "Concentrez-vous sur les tests avec p-value < 0.05 qui indiquent des relations significatives.",
            "tts_text": f"{len(eda_data.get('tests', []))} tests statistiques ont √©t√© r√©alis√©s. Les r√©sultats avec p-value inf√©rieure √† 0.05 sont statistiquement significatifs."
        },
        "clustering": {
            "title": "Segmentation Intelligente",
            "summary": f"Analyse de clustering pour identifier des groupes naturels dans les donn√©es.",
            "recommendation": "Les donn√©es n'ont pas form√© de clusters distincts. Essayez avec d'autres variables ou consultez les visualisations.",
            "tts_text": "L'analyse de clustering n'a pas identifi√© de groupes tr√®s distincts. Les donn√©es sont trop dispers√©es ou n'ont pas de structure de clustering claire. Essayez d'explorer d'autres variables ou d'utiliser des approches alternatives.",
            "details": {
                "qualite_clustering": "faible",
                "nombre_groupes_optimal": "Non applicable",
                "caracteristiques_cles": ["Donn√©es dispers√©es"],
                "applications": ["Essayer d'autres variables", "Consid√©rer d'autres m√©thodes"]
            }
        },
        "correlation": {
            "title": "Matrice de Corr√©lation",
            "summary": f"Analyse des relations lin√©aires entre variables. {len(eda_data.get('correlations', {}).get('strong_correlations', []))} corr√©lations fortes identifi√©es.",
            "recommendation": "V√©rifiez les corr√©lations avec la variable cible pour identifier les pr√©dicteurs potentiels.",
            "tts_text": "La matrice de corr√©lation montre les relations lin√©aires entre variables. Les corr√©lations fortes (proches de 1 ou -1) indiquent des relations importantes."
        }
    }
    
    explanation = fallbacks.get(task_id, {
        "title": task_id.title(),
        "summary": f"Analyse pour {context.get('target_variable', 'cible')}",
        "recommendation": "Consultez les donn√©es d√©taill√©es ci-dessous",
        "tts_text": f"Voici l'analyse pour l'onglet {task_id}."
    })
    
    return explanation


async def generate_tab_explanations_async(eda_data: Dict[str, Any],
                                          context: Dict[str, Any]) -> Dict[str, Any]:
    """
    G√©n√®re les explications avec MULTI-LLM:
    1. Claude (Anthropic)
    2. Gemini (Google)
    3. GPT-4 (OpenAI)
    4. Fallback par d√©faut
    
    ‚úÖ FIX: G√®re le cas o√π multi_clustering est None
    """
    
    tasks = TabExplanationsGenerator.create_tab_explanation_tasks(eda_data, context)
    
    logger.info(f"ü§ñ G√©n√©ration {len(tasks)} explications avec Multi-LLM")
    
    tab_explanations = {}
    
    for task in tasks:
        logger.info(f"üìù G√©n√©ration: {task['task_id']}")
        
        # Essayer les 3 LLM en parall√®le
        results = await asyncio.gather(
            _call_anthropic(task["prompt"]),
            _call_gemini(task["prompt"]),
            _call_gpt4(task["prompt"]),
            return_exceptions=True
        )
        
        # Prendre le premier r√©sultat valide
        explanation = None
        for i, (result, llm_name) in enumerate(zip(results, ["Claude", "Gemini", "GPT-4"])):
            if isinstance(result, dict) and result.get("title"):
                logger.info(f"‚úÖ {llm_name} utilis√© pour {task['task_id']}")
                explanation = result
                break
        
        # Fallback si tous √©chouent
        if not explanation:
            logger.warning(f"‚ö†Ô∏è Tous les LLM ont √©chou√© pour {task['task_id']}, fallback")
            explanation = await _generate_fallback_explanation(task['task_id'], context, eda_data)
        
        tab_explanations[task["task_id"]] = explanation
    
    logger.info(f"‚úÖ {len(tab_explanations)} explications g√©n√©r√©es")
    return tab_explanations